\section{Data Management}
\label{data}

\fixme{(authors: Anders, Brian, Maxim, Mike, Simon)}

\subsection{Definition}
Data Management is any content neutral interaction with the data and includes Data Storage/Archival, Access, 
Distribution and Curation. It includes technical solutions, procedures and policies and deals with the full life 
cycle of the data. 



\subsubsection{Metadata}
To be able to manage the data it has to be described. Metadata is therefore a necessary part of data management. The 
list of possible metadata is long, but a few key ones are 'Data provenance' and 'Data file location' since they map onto 
applications like file managers and data catalogs and their possible ties to workflow management.

\subsubsection{Data catalogs And Logical Data Sets}
A data catalog combines a file catalog i.e. information about where the data files are stored, with additional metadata.
This enables the construction of logical (virtual) data sets like 'Higgs2GammaGamma' and makes it possible for users to 
make a selection of a subset of the available data.

\begin{description}
\item[Fermi Data Catalog] One way to do this is to register all the metadata when you register the file. A slightly
different approach was chosen by the Fermi Space Telescope Data Catalog. In addition to the initial metadata, it had a
data crawler that would go through all registered files and extract metadata like number of events etc. The advantage is
that the set of metadata then can be easily expanded after the fact - you just let loose the crawler with the list
of new quantities to extract. Note that since the Fermi Data Catalog is independent of any workflow management system, 
any data processing metadata will have to be explicitly added. 


\item[SAM] [more detailed description - SAM is more tied into workflow management than the Fermi Data catalog]

\item[ATLAS] ....

\item[CMS] ....

\end{description}


\subsubsection{File Catalogs and Federated Storage/XRootD}
One interesting evolution is the use of XRootD and Federated Storage. A traditional file catalog will contain the 
location of the data files. With XRootD the notion of location is outsourced to the XRootD director. 
[awb: more details ....]


\subsection{Data distribution}

\subsubsection{Data Skimmers}
A Data Catalog can be combined with a workflow engine to produce skims. These can be either user skims or collaboration 
wide skims. 

\begin{description}
\item[Fermi data skimmer] Even though the Fermi Data Catalog is independent of any workflow management system, it 
can be chained together with for example the Fermi workflow engine ('pipeline') to easily produce user defined skims 
i.e. the user selects cuts and what logical data sets to use and the relevant file locations are automatically 
forwarded to the processing pipeline that produce the requested output files and make them available for download 
by the user. 

\item[Pointer skims] (Needed?) Instead of producing new deep copies of skimmed files one can instead make a list 
containing 
pointers to events in the original data files. This was, for example, done by the BaBar pointer skims. While it has 
certain advantages, like minimizing duplication of data, it has possible I/O and latency issues. In addition, it's not 
clear how this works with the Federated Storage model.
\end{description}

\subsubsection{Authentication/Authorization} This is a potential touchy subject ....  


\subsubsection{Hot Datasets}
All data are not created equal. There will inevitably be hot data sets (Higgs skims for example) accessed often and by 
many. There will also be colder data sets rarely accessed at all. The temperature of the different datasets maps  
naturally onto different storage technology. For example, in a three-tiered system the hot datasets are stored on SSD, 
warm datasets are stored on fast disks and cold datasets are stored on slow disks or tape. XRootD makes the 
management of such a system easier as it can be configured to automatically retrieve datasets from tape in case they 
don't exist on disk. Note that such a system is dynamic i.e. today's hot dataset is tomorrow's cold one so datasets will 
need to be automatically migrated from one storage layer to the following one based on access patterns. [add some details about the ATLAS/CMS systems for caching and purging] 



\subsubsection{What Works, What Doesn't}
[Needs to be expanded] One danger with DM systems is that they become monolithic - especially over time - as more 
and more functionality is added and there is a desire to make the overall system easier to use (automating more 
and more functions). Maybe somebody has some experience with how LHC experiments have tried to make things modular?


\subsubsection{Common Elements vs Experiment Specific Ones}



\subsubsection{Editing notes}

\fixme{This is not a real section and will be deleted}

\begin{itemize}
\item Define data management and it's major elements (one suggestion is below)
\item reference that it is related to workflow management
\item List ways that DM can tend to be particularly parochial and how in some cases it must be specifically tailored to the computing facility and/or experiment.
\item List what elements are general.
\item Take care not to overlap with the systems group, but to point out where there are areas of overlap.
\end{itemize}
Possible partitioning of DM into smaller parts:
\begin{description}
\item[Distribution] issues:
  \begin{itemize}
  \item authentication/authorization
  \item caching / purging
  \item side hardware and software requirements
  \item on-demand vs. scheduled
  \end{itemize}
\item[Metadata] issues:
  \begin{itemize}
  \item What job produced what file and with what input parameters/data
  \item Where is my file? Data catalogs ...
  \item Fileset definitions
  \item File popularity to drive cache purges
  \item Important analysis summary info
  \item Locating files/events/objects
  \item Everything as metadata
  \item Provenance tracking
  \item Namespace issues
  \end{itemize}
\end{description}



\subsection{Description}
\subsection{What works, what doesn't}
\subsection{Examples}
\subsection{Opportunity for improvement}
